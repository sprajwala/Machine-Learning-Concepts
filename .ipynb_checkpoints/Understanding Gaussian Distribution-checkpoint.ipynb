{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as spla\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a random Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a generic function to generate 10000 samples from the standard multivariate Gaussian distribution. Will use this function further down to generate for d=3 and plot the histogram of its Euclidean norms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a standard distribution, hence we want mean $$ \\mu = 0 $$  $$ covariance = 1 $$\n",
    "Hence we take an array of zeros as mean and an identity matrix of size d as covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will generate a (10000 x d) matrix of random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate 10000 random samples in d dimensions\n",
    "def generate_random_sample(d):\n",
    "    mean = np.zeros(d)\n",
    "    cov = np.identity(d)\n",
    "    samples = np.random.multivariate_normal(mean,cov,10000)\n",
    "    \n",
    "    #calculating norms, mean, standard deviation\n",
    "    norms = euclidean_norm(samples)\n",
    "    sample_mean = np.mean(norms)\n",
    "    std = np.std(norms)\n",
    "    \n",
    "    return(sample_mean,std,norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate euclidean norms of a set of samples\n",
    "def euclidean_norm(samples):\n",
    "    norms  = []\n",
    "    for row in samples:\n",
    "        sum_sq =0\n",
    "        for dim in range(d):\n",
    "            sum_sq += row[dim]**2\n",
    "        norms.append(math.sqrt(sum_sq))\n",
    "    return(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [1,2,3,10,20,50,100,200,350,500,750,1000]\n",
    "all_means = []\n",
    "all_std = []\n",
    "for d in ds:\n",
    "    mean,std,norms = generate_random_sample(d)\n",
    "    all_means.append(mean)\n",
    "    all_std.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28932517860>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ds,all_means,'o')\n",
    "plt.plot(ds,all_std,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing variation of mean and standard deviation as dimention increases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above plot that as we increase dimension drastically, the mean is increasing in almost natural log way  but at the same time, the standard deviation does not change much at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can draw a conclusion that the spread of a gaussian distribution is independent of the dimension of the determining parameters. That is, if we are able to generate a distribution at a say a high confidence level, then that level does not change with change in dimension.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Plotting for \n",
    " $$d = 3 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot the histogram of samples and mean line.\n",
    "def plot_hist_norms(norms,bin_size):\n",
    "    plt.hist(norms, bins = bin_size)\n",
    "    plt.axvline(sum(norms)/len(norms),color='r',linewidth=2)\n",
    "    plt.xlabel('Euclidean norms')\n",
    "    plt.ylabel('Samples')\n",
    "    plt.np.std(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6032744408828705 0.6801005316551701\n",
      "1.6032744408828705 0.6801005316551701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28932375278>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVDklEQVR4nO3df7BkZX3n8fdHJAGXbMDlQo3DsOMapAQMg0wQJZsouAmiFbAWDNQGSZZ1UhXYxZS1G7Rqy2hkgybKriZFMgoyJgZkF11RrMgEAc0moDM4/BxdJ0pklikYFkRcDWaG7/7R5x6b4c5Mz8w9ffrefr+qbvXpp093f/vC9Oc+z3POc1JVSJIE8Ly+C5AkTQ5DQZLUMhQkSS1DQZLUMhQkSa3n913Avjj00ENr+fLlfZeh+bZ+/eD2xBP7rUNapNavX/9YVc3M9diCDoXly5ezbt26vsvQfEsGt/63lTqR5O939pjDR5KklqEgSWoZCpKkVmehkOSAJF9JcneS+5O8u2l/cZI7k3wzySeT/ETT/pPN/U3N48u7qk2SNLcuewpPA6dW1fHACuD0JCcD7wOuqKqjgCeAC5v9LwSeqKqfAa5o9pMkjVFnoVAD32/u7t/8FHAq8D+a9jXAWc32mc19msdPS2YPQ5EkjUOncwpJ9kuyAXgUWAv8HfDdqtrW7LIZWNpsLwUeAmgefxL4Z3O85qok65Ks27p1a5flS9LU6TQUqmp7Va0AjgBOAl42127N7Vy9gues611Vq6tqZVWtnJmZ89wLSdJeGsvRR1X1XeA24GTg4CSzJ80dATzcbG8GlgE0j/808Pg46pMkDXR59NFMkoOb7QOB1wEbgVuBs5vdLgA+02zf2NynefyL5RWAJs7yS29qfyQtPl0uc7EEWJNkPwbhc31VfS7JA8B1Sd4LfA24qtn/KuDPkmxi0EM4t8Pa1KHhwHjw8jf0WImkPdVZKFTVPcAJc7R/i8H8wo7t/wCc01U9kqTd84xmSVLLUJAktQwFSVJrQV9PQePhkUbS9LCnIElqGQqSpJahIElqGQqSpJahIElqefSR9prLWUiLjz0FSVLLUJAktQwFSVLLOQXNC896lhYHQ0ELgpPa0ng4fCRJahkKkqSWoSBJahkKkqSWE82aUxdHEzlZLE0+Q0ELjuEidcdQUKc8f0FaWJxTkCS17Cmodw4HSZPDnoIkqWUoSJJanYVCkmVJbk2yMcn9SS5p2n83yf9JsqH5OWPoOe9IsinJN5L8cle1SZLm1uWcwjbg7VV1V5KfAtYnWds8dkVV/eHwzkmOAc4FjgVeBPxVkpdW1fYOa1RPPCpJmkyd9RSqaktV3dVsPwVsBJbu4ilnAtdV1dNV9W1gE3BSV/VJkp5rLHMKSZYDJwB3Nk0XJ7knydVJDmnalgIPDT1tM3OESJJVSdYlWbd169YOq5ak6dN5KCQ5CLgBeFtVfQ+4EngJsALYAnxgdtc5nl7PaahaXVUrq2rlzMxMR1VL0nTqNBSS7M8gED5RVZ8CqKpHqmp7VT0DfIQfDxFtBpYNPf0I4OEu65MkPVuXRx8FuArYWFUfHGpfMrTbm4D7mu0bgXOT/GSSFwNHAV/pqj5J0nN1efTRKcD5wL1JNjRt7wTOS7KCwdDQg8BvAlTV/UmuBx5gcOTSRR55JEnj1VkoVNVfM/c8wed38ZzLgMu6qkmStGue0SxJahkKkqSWq6ROocW0Kuli+izSJLCnoIni8hdSv+wpaGLNZ0DYo5BGYyho0fCLX9p3Dh9Jklr2FNRyPF+SPQVJUstQkCS1DAVJUstQkCS1nGieEtM2iTxtn1eaL/YUJEktQ0GS1HL4aMo5zCJpmD0FSVLLUJAktQwFSVLLUJAktZxo1tRxiW1p5+wpSJJahoIkqWUoSJJahoIkqWUoSJJanYVCkmVJbk2yMcn9SS5p2l+YZG2Sbza3hzTtSfKhJJuS3JPkFV3VJkmaW5c9hW3A26vqZcDJwEVJjgEuBW6pqqOAW5r7AK8Hjmp+VgFXdlibJGkOnYVCVW2pqrua7aeAjcBS4ExgTbPbGuCsZvtM4OM1cAdwcJIlXdUnSXqusZy8lmQ5cAJwJ3B4VW2BQXAkOazZbSnw0NDTNjdtW3Z4rVUMehIceeSRnda9UHgylqT50vlEc5KDgBuAt1XV93a16xxt9ZyGqtVVtbKqVs7MzMxXmZIkOg6FJPszCIRPVNWnmuZHZoeFmttHm/bNwLKhpx8BPNxlfZKkZ+ts+ChJgKuAjVX1waGHbgQuAC5vbj8z1H5xkuuAVwJPzg4zaXReNEfSvuhyTuEU4Hzg3iQbmrZ3MgiD65NcCHwHOKd57PPAGcAm4AfAb3RYmyRpDp2FQlX9NXPPEwCcNsf+BVzUVT2SpN1z6WxNNY/ckp7NZS4kSS1DQZLUMhQkSS1DQZLUcqJZajjpLNlTkCQNGSkUkrw/yT9Nsn+SW5I8luTXui5OkjReo/YUfqlZzO6NDNYoeinwHzurSpLUi1FDYf/m9gzg2qp6vKN6JEk9GnWi+bNJvg78EPitJDPAP3RXliSpDyP1FKrqUuBVwMqq+kcGC9ad2WVhkqTxG3Wi+QUMFqubvW7yi4CVXRUlSerHqHMKHwN+BLy6ub8ZeG8nFUmSejNqKLykqt4P/CNAVf2QnS+LLUlaoEYNhR8lOZDmmslJXgI83VlVkqRejHr00buAvwSWJfkEg6uq/XpXRUmTxOUvNE1GCoWqWpvkLuBkBsNGl1TVY51WJkkau12GQpJX7NC0pbk9MsmRVXVXN2VJkvqwu57CB3bxWAGnzmMtkqSe7TIUquq14ypEktS/keYUkhwA/Bbw8wx6CF8G/qSqXOpCkhaRUY8++jjwFPDh5v55wJ8B53RRlCSpH6OGwtFVdfzQ/VuT3N1FQZKk/ox68trXkpw8eyfJK4H/1U1JkqS+jNpTeCXwliTfae4fCWxMci9QVfWznVQn9WT4hDVpmowaCqfv6QsnuZrBldoerarjmrbfBd4KbG12e2dVfb557B3AhcB24D9U1Rf29D0lSftm1DOa/z7JIcCy4efs5uS1a4A/YjBJPeyKqvrD4YYkxwDnAscyWJb7r5K8tKq2j1LfNPIvWUldGPWQ1N9jsNbR39EsisduTl6rqi8lWT5iHWcC11XV08C3k2wCTgL+dsTnS5LmwajDR29msHz2j+bhPS9O8hZgHfD2qnoCWArcMbTP5qbtOZKsAlYBHHnkkfNQjiRp1qhHH90HHDwP73cl8BJgBYN1lGaX0Zjr2gw1RxtVtbqqVlbVypmZmXkoSRrd8ktvan+kxWjUnsLvMzgs9T6GrqNQVb+yJ29WVY/Mbif5CPC55u5mBvMVs44AHt6T15Yk7btRQ2EN8D7gXuCZvX2zJEuqanal1Tcx6IEA3Aj8RZIPMphoPgr4yt6+jyRp74waCo9V1Yf25IWTXAu8Bjg0yWYGF+p5TZIVDIaGHgR+E6Cq7k9yPfAAsA24yCOPtJB4IR4tFqOGwvokv8/gL/rh4aOdHpJaVefN0XzVLva/DLhsxHokSR0YNRROaG5PHmrzegqStMiMevKa11WQpCkwak+BJG9gcMbxAbNtVfWeLoqSJPVj1DOa/wR4AfBa4KPA2Xh0kDQnJ521kI168tqrq+otwBNV9W7gVTz7vAJJ0iIwaij8sLn9QZIXMThs9MXdlCRJ6suocwqfS3Iw8H5gfdP20W5K0s64tIKkru0yFJL8HPBQVf1ec/8gBmc1fx24ovvyJEnjtLuewp8CrwNI8gvA5cC/Z7Cg3WoGE87SVLLnpsVod6GwX1U93mz/KrC6qm4AbkiyodvSJEnjtttQSPL8qtoGnEZzHYMRnytNPQ9P1UKzuy/2a4HbkzzG4AikLwMk+RngyY5rkySN2S5DoaouS3ILsAS4uapmL3zzPAZzC5KkRWS3Q0BVdcccbf+7m3IkSX0a9eQ1SdIUMBQkSS1DQZLUMhQkSS1DQZLU8gS0CeFJTpImgaEgjYnBr4XAUJhAfnlI6ouhMOFciVPSOBkKUg/sDWpSefSRJKllKEiSWp2FQpKrkzya5L6hthcmWZvkm83tIU17knwoyaYk9yR5RVd1SZJ2rsuewjXA6Tu0XQrcUlVHAbc09wFeDxzV/KwCruywLmmiLL/0pvZH6ltnoVBVXwIe36H5TGBNs70GOGuo/eM1cAdwcJIlXdUmSZrbuOcUDq+qLQDN7WFN+1LgoaH9Njdtz5FkVZJ1SdZt3bq102IladpMykRz5mirOdqoqtVVtbKqVs7MzHRcliRNl3GHwiOzw0LN7aNN+2Zg2dB+RwAPj7k2SZp64w6FG4ELmu0LgM8Mtb+lOQrpZODJ2WEmSdL4dHZGc5JrgdcAhybZDLwLuBy4PsmFwHeAc5rdPw+cAWwCfgD8Rld1SZJ2rrNQqKrzdvLQaXPsW8BFXdUiSRqNax/1yOPStSuuj6Q+TMrRR5KkCWAoSJJaDh9JE8QhRfXNUJAWAOcXNC4OH0mSWvYUxszhAUmTzJ6CJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWi5zMQYubSFpoTAUpAVmZ39kuHqq5oPDR5KklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKkVi/nKSR5EHgK2A5sq6qVSV4IfBJYDjwIvLmqnuijPkmaVn2evPbaqnps6P6lwC1VdXmSS5v7v9NPadLCM3xSmyeyaW9N0vDRmcCaZnsNcFaPtUjSVOorFAq4Ocn6JKuatsOragtAc3vYXE9MsirJuiTrtm7dOqZyJWk69DV8dEpVPZzkMGBtkq+P+sSqWg2sBli5cmV1VaAkTaNeegpV9XBz+yjwaeAk4JEkSwCa20f7qE2SptnYewpJ/gnwvKp6qtn+JeA9wI3ABcDlze1nxl3bfHK5bEkLUR/DR4cDn04y+/5/UVV/meSrwPVJLgS+A5zTQ22SNNXGHgpV9S3g+Dna/y9w2rjrkST92CQdkipJ6plXXptHziNIWugMBWmKeClP7Y6hIOlZXC5juhkK+8ghI00iv9i1t5xoliS17ClIi9wovVl7vJplT0GS1DIUJEkth48kjcTJ6+lgT0GS1DIUJEkth48k7TGHkhYvQ0HSPjEgFhdDQdJOef7C9HFOQZLUsqewF/zrSdJiZShImjfOLyx8Dh9JklqGgiSp5fCRpM45rLRwGAqSxsqAmGyGgqTeGBCTx1AYkYehSntmT//N7Gx/w2K8DIVdMAgkTRtDYQcGgbTwjPLv1h7HaCbukNQkpyf5RpJNSS7tux5JmiYT1VNIsh/wx8C/AjYDX01yY1U90OX72juQJtd8/fvcm95EFz2QSZ9cn6hQAE4CNlXVtwCSXAecCXQaCpIEexdAO/uSH+W19jQgxhEoqapOXnhvJDkbOL2q/l1z/3zglVV18dA+q4BVzd2jgW/s5dsdCjy2D+UuBtP+O/DzT/fnh+n9HfzzqpqZ64FJ6ylkjrZnpVZVrQZW7/MbJeuqauW+vs5CNu2/Az//dH9+8Hcwl0mbaN4MLBu6fwTwcE+1SNLUmbRQ+CpwVJIXJ/kJ4Fzgxp5rkqSpMVHDR1W1LcnFwBeA/YCrq+r+jt5un4egFoFp/x34+eXvYAcTNdEsSerXpA0fSZJ6ZChIklpTGQrTvpRGkquTPJrkvr5r6UOSZUluTbIxyf1JLum7pnFKckCSryS5u/n87+67pj4k2S/J15J8ru9aJsnUhcLQUhqvB44BzktyTL9Vjd01wOl9F9GjbcDbq+plwMnARVP2/8DTwKlVdTywAjg9yck919SHS4CNfRcxaaYuFBhaSqOqfgTMLqUxNarqS8DjfdfRl6raUlV3NdtPMfhiWNpvVeNTA99v7u7f/EzVESdJjgDeAHy071omzTSGwlLgoaH7m5miLwQ9W5LlwAnAnf1WMl7N0MkG4FFgbVVN1ecH/ivwn4Bn+i5k0kxjKOx2KQ1NhyQHATcAb6uq7/VdzzhV1faqWsFg1YCTkhzXd03jkuSNwKNVtb7vWibRNIaCS2mIJPszCIRPVNWn+q6nL1X1XeA2pmuO6RTgV5I8yGD4+NQkf95vSZNjGkPBpTSmXJIAVwEbq+qDfdczbklmkhzcbB8IvA74er9VjU9VvaOqjqiq5Qz+/X+xqn6t57ImxtSFQlVtA2aX0tgIXN/hUhoTKcm1wN8CRyfZnOTCvmsas1OA8xn8hbih+Tmj76LGaAlwa5J7GPyRtLaqPCxTgMtcSJKGTF1PQZK0c4aCJKllKEiSWoaCJKllKEiSWoaCFqQk24cOJ92wt6vdJnkwyaHN9t/sZJ9rkpy9L/VKC8VEXY5T2gM/bJZpmDdV9er5fL1xSfL85vwbaZ/ZU9CissNf/iuT3NZsH5TkY0nuTXJPkn89x3O/39wmyR8leSDJTcBhQ/ucmOT2JOuTfCHJkqb9rUm+2lyj4IYkL2jar0nyoSR/k+Rbc/U4kixvru3wkeb6Bjc3ZxqTZEWSO5qaP53kkKb9tiT/JcntwCXN+1zZXCfiW0l+sbluxsYk1zTP2a/Z777m9/Db8/m71+JgKGihOnCH4aNf3c3+/xl4sqpeXlU/C3xxF/u+CTgaeDnwVuDV0K6X9GHg7Ko6EbgauKx5zqeq6ueaaxRsBIbPEl8C/DzwRuDynbznUcAfV9WxwHeB2dD6OPA7Tc33Au8aes7BVfWLVfWB5v4hwKnAbwOfBa4AjgVenmQFg2snLK2q46rq5cDHdvE70JRy+EgL1Z4OH72OwTo3AFTVE7vY9xeAa6tqO/BwktkAORo4Dlg7WD6J/YAtzWPHJXkvcDBwEINlVGb9z6p6BnggyeE7ec9vV9WGZns9sDzJTzP44r+9aV8D/Peh53xyh9f4bFVVknuBR6rqXoAk9wPLgduBf5Hkw8BNwM27+B1oShkKWmy28eMe8AFD7WHPlkifa98A91fVq+Z47BrgrKq6O8mvA68ZeuzpHV5jLsP7bAcOHKHG/7eT13hmh9d7Bnh+VT2R5Hjgl4GLgDcD/3aE99EUcfhIi82DwInN9vC8wc0MFkIEYHZsfie+BJzbjMEvAV7btH8DmEnyquY19k9ybPPYTwFbmiGmf7PPnwKoqieBJ5L8y6bpfAZ/7e+VZq7leVV1A4PhtFfse5VabAwFLVQ7zinMjtW/G/hvSb7M4C/uWe8FDmkmWe/mx1/0c/k08E0GY/hX0nwRN5dvPRt4X/MaG2jmGxh8yd4JrGV+l6G+APiDZkXTFcB79uG1lgK3NVdcuwZ4x76Xp8XGVVIlSS17CpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKk1v8HgaTtyaeOQ68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m,sd,mynorms = generate_random_sample(3)\n",
    "print(m,sd)\n",
    "plot_hist_norms(mynorms,100)\n",
    "plt.plot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## References:\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prajw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser to read each document and convert it into vector of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data a little by converting all words to lowercase and removing puncuations because that does not affect similarity of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\prajw\\\\Machine Learning NYU\\\\data\\\\\"\n",
    "all_docs = {}\n",
    "stemmer = PorterStemmer\n",
    "i=0\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = subdir + os.path.sep + file\n",
    "        docs = open(file_path,'r')\n",
    "        text = docs.read()\n",
    "        lowers = text.lower()\n",
    "        no_punctuation = lowers.translate(string.punctuation)\n",
    "        all_docs[i] = no_punctuation\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english') #removing standard english stop words from the corpus of words to process\n",
    "tfs = tfidf.fit_transform(all_docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 472)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorizer gives us a scipy.sparse.csr.csr_matrix of size (6 x 472) because it has calculated the TF\\*IDF score for each word in the corpus against each document. If a word is not at all present in a document, its score is 0. Hence this is a sparse matrix because there will be a lot of such zero values for very distinct set of documents.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have converted this sparse matrix to dense and printed each of the words for which the score was computed. Document at index 5 is the d_query.txt document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>040</th>\n",
       "      <th>141</th>\n",
       "      <th>15</th>\n",
       "      <th>1812</th>\n",
       "      <th>1814</th>\n",
       "      <th>1815</th>\n",
       "      <th>1816</th>\n",
       "      <th>1817</th>\n",
       "      <th>1827</th>\n",
       "      <th>...</th>\n",
       "      <th>william</th>\n",
       "      <th>wooden</th>\n",
       "      <th>wora</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>yards</th>\n",
       "      <th>years</th>\n",
       "      <th>yemen</th>\n",
       "      <th>york</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128284</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.128284</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128284</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000       040       141        15      1812      1814      1815  \\\n",
       "0  0.000000  0.000000  0.086207  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.065249  0.000000  0.065249  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.128284  0.064142  0.128284   \n",
       "3  0.064316  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       1816      1817      1827  ...   william    wooden      wora     world  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.086207   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.064142  0.064142  0.064142  ...  0.128284  0.064142  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.068622  0.000000   \n",
       "5  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      write     yards     years     yemen      york      zone  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.065249  \n",
       "2  0.000000  0.064142  0.000000  0.000000  0.064142  0.000000  \n",
       "3  0.000000  0.000000  0.064316  0.064316  0.000000  0.000000  \n",
       "4  0.068622  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[6 rows x 472 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfs.todense(),columns =tfidf.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the cosine similarity of each document with respect to the query document which is at column index 5  in the dataframe df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the score on column 5 is 1 as it should be because the document matches completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving the query document out, we get the highest value for cosine similarity as 0.381183 for document d_4.txt present on column 3 as seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the highest score as the most similar because that means it has the smallest cosine angle between the two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09939</td>\n",
       "      <td>0.065823</td>\n",
       "      <td>0.073951</td>\n",
       "      <td>0.381183</td>\n",
       "      <td>0.118673</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4    5\n",
       "0  0.09939  0.065823  0.073951  0.381183  0.118673  1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_df = pd.DataFrame(cosine_similarity(tfs[5],tfs))\n",
    "cos_sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the document to which the query document was most similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java coffee refers to coffee beans produced in the indonesian island of java.  the indonesian phrase kopi java refers not only to the origin of the coffee, but is used to distinguish a style of strong, black, and very sweet coffee.  in some countries, java can refer to coffee in general.++the coffee is primarily grown on large estates that were built by the dutch in the 18th century. the five largest estates are blawan (also spelled belawan or blauan), jampit (or djampit), pancoer (or pancur), kayumas and tugosari, and they cover more than 4,000 hectares.++these estates transport ripe cherries quickly to their mills after harvest. the pulp is then fermented and washed off, using the wet process, with rigorous quality control. this results in coffee with good, heavy body and a sweet overall impression. they are sometimes rustic in their flavor profiles, but display a lasting finish. at their best, they are smooth and supple and sometimes have a subtle herbaceous note in the after-taste.++this coffee is prized as one component in the traditional \"mocca java\" blend, which pairs coffee from yemen and java. certain estates age a portion of their coffee for up to five years, normally in large burlap sacks, which are regularly aired, dusted, and flipped. as they age, the beans turn from green to light brown, and their flavor gains strength while losing acidity. aged coffees can display flavors ranging from cedar to spices such as cinnamon or clove, and often develop a thick, almost syrupy body. these aged coffees are called old government, old brown or old java.+'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = cos_sim_df.iloc[:,:-1].idxmax(axis=1).tolist()\n",
    "all_docs[val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
